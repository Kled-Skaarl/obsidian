### 1. Conditional DETR for Fast Training Convergence
 *ICCV 2021*

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013201710.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013201824.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013202720.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013202930.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013203007.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013203121.png)

对比DAB-DETR：
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241013203343.png)

### 2. Relation DETR: Exploring Explicit Position Relation Prior for Object Detection
ECCV 2024

在DETR编码器中引入了位置关系编码器来建模两个边界框之间的所有成对交互。
物体在目标检测任务中真的相关吗？

基于皮尔逊系数的位置相关性度量：

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016200615.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016200849.png)

所有这些数据集都表明MC的分布集中在高数值附近，分布中心更接近上限。这证明了对象位置关系的存在和统计意义。具体来说，特定于任务的数据集在高维特征空间中显示更多的先验知识和更清晰的聚类模式，因此比 COCO 等通用数据集具有更高的 MC 值。

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016201018.png)

相对位置embeding
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016201246.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016201310.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016201324.png)

添加到注意力中：

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016201556.png)
为了解决非重复预测和充分的正向监督之间的冲突，引入了两个并行查询集：匹配查询$Q_m$和混合$Q_h$，
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202220.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202337.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202415.png)
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202440.png)

coco数据集上：![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202527.png)

特定任务的缺陷检测数据集CSD上：![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241016202647.png)

### 3. Do Topological Characteristics Help in Knowledge Distillation?
ICML 2024

本文提出了一种名为 TopKD 的新型 KD 方法，它考虑了潜在空间的全局拓扑。通过使用持久性图（PD）定义全局拓扑知识，持久性图捕获全面的几何结构，例如分布形状、多尺度结构和连通性，以及用于教授这些知识的拓扑蒸馏损失。
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015215415.png)

**Persistence Diagrams(PD)**
常见的拓扑特征包括：
- **连通分支**：数据集中彼此连接的点集数量。
- **空洞（循环）**：例如二维中的环形区域。
- **空腔**：三维空间中的空洞。
在拓扑数据分析（TDA）中，**Persistence Diagrams**是用于表示空间中拓扑特征随尺度变化的方式，它们通过计算不同尺度上的同调群（homology groups，例如连通分支、循环、空腔）来观察空间的拓扑特征在不同尺度上是如何出现和消失的。

构造PD：

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015215843.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015215951.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015220024.png)

对构造的PD向量化，得到PI(Persistence Image)
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241025095258.png)
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015220156.png)
$w(u)$是权重函数，$g_u(z)$是高斯函数。
但是准确计算每批的 PD 和 PI 需要大量的计算量。因此，TopKD 使用 RipsNet 近似 PI 来解决这个问题。

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015222523.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015222459.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241015222600.png)

### 4. Improving Transformers with Dynamically Composable Multi-Head Attention
*ICML 2024*

通过**动态组合注意力头**来提高模型的表达能力。

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024104638.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024104835.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024105342.png)
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024105357.png)
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024105411.png)

上述 Compose 的计算相当于对 W 进行两级分解，以减少参数和提高计算效率：
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024110802.png)

先沿着行和列进行分解，再低秩和对角分解
![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024111224.png)

![](https://cdn.jsdelivr.net/gh/Kled-Skaarl/Picturebed@master/notes/20241024111646.png)


#### To do
1. query分组
2. 工业缺陷检测数据集？
3. high_map images of coco